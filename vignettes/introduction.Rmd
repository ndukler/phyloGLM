---
title: "Introduction to phyloGLM"
author: "Noah Dukler"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

First create some data and a tree. Pretend that sites are split into two classes, "Enhancer" and "Promoter" and also split by ontology classes "A" and "B".

```{r}
library(phyloGLM)
library(cowplot)
## Set seed for consistency
set.seed(123)
## Set some parameters for the simulation
species=c("A","B","C","D","E")
nAlleles=3
nSites=1000

## Create test trees, both one that will fail, and one that will pass
tree=ape::rtree(n = length(species),tip.label = species)

## Create a covariate data.frame with labels
siteLabels=data.frame(cre.class=factor(rep(c("Enhancer","Promoter"),times=c(3/4*nSites,1/4*nSites))),
                      logXpress = rnorm(n = nSites, mean = 0 , sd = 1))
## Set the rate parameter formula
rateFormula = formula(~cre.class+logXpress+0)
## Set parameter values
rateParams=matrix(c(-1,-4.5,-3.3),nrow=1)
piParams=matrix(c(0.3,0.1,0,0,-0.1,0.5),nrow=2,ncol=3,byrow = T)
## Simulate data
aData=simulateSites(tr=tree,covariateTable = siteLabels,rateFormula = rateFormula, rateParams = rateParams,
                    piParams = piParams)
```
Now create the allele data object:

```{r,echo=FALSE}
ad=alleleData(data=aData$data,tree=tree,siteInfo = siteLabels)
```

Now create a rate model specifying that genomic regions should be seperated by both cre.class and go.class.

```{r}
rateMod=rateModel(data = ad,rateFormula=rateFormula)
```
Note that the likelihood calculations in this package scale well when parallelized up to one or two less than the number of available threads on your system.
```{r}
m=microbenchmark::microbenchmark(ll(model = rateMod,threads = 1),
                               ll(model = rateMod,threads = 2),
                               ll(model = rateMod,threads = 3))
m=as.data.frame(m)
ggplot(m,aes(x=factor(as.numeric(m$expr)),y=time/10^6))+
  geom_boxplot()+
  ylab("Time for log-likelihood evaluation (ms)")+
  xlab("Threads")+
  ylim(0,max(m$time/10^6))
```

Now we can fit the model:

```{r}
fitted_status<-fit(model = rateMod,threads=3)
```

Once fitted we can extract the parameters, their approximate standard errors and plot them:

```{r}
seTab=se(rateMod,fitted_status$hessian)
plotParams(seTab)
```
We can also compute the posterior allelic probabilties accross all nodes
```{r}
m=marginal(rateMod)
```
To get explicit p-values for specific parameters we can use the likelihood ratio test (since estimating the standard error via the hessian may not be reliable). To do that we must fit two models, one with (alternate model), and one without (null model) the parameter of interest (in this case the alternate model is the model we previously fit). Note how we are careful to set the formulas for the rate and stationary distributions seperately to ensure that the models differ by only one parameter. The models must also be nested in order for this test to be valid. A small p-value rejects the null model, concluding that the more complex model fits the data better, even given the additional degrees of freedom.

```{r}
nullFormula = formula(~cre.class+0)
alternateFormula = formula(~cre.class+logXpress+0)
rateModNull=rateModel(data = ad,rateFormula=nullFormula,piFormula = alternateFormula)
fitted_status_alternate=fit(rateModNull,threads = 3)
lrt_expression=lrt(h0 = rateModNull,hA = rateMod)
```
Models may also be compared usng the baysian information criterion (BIC) which does not require that the models be nested. The lower the BIC the better the model, in other words if BIC(alternate) < BIC(null), we can conclude that the alternate model provides a better fit to the data. In this case we perform BIC(alternate)-BIC(NULL), see a large negative value, and conclude that the alternate model is better.  

```{r}
bic(rateMod)-bic(rateModNull)
```

